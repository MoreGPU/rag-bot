{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of using RAGBot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/openai/openai-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "sys.path.append('../utils/')\n",
    "\n",
    "from config import *\n",
    "from typing import List\n",
    "from azure_utils import CustomAzureSearch\n",
    "from openai_utils import RAGBot, OpenAIChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLOps, short for Machine Learning Operations, refers to the practices and processes used to develop, deploy, and manage machine learning models in a production environment. It aims to bridge the gap between data science and IT operations by applying DevOps principles to machine learning workflows.\n",
      "\n",
      "MLOps helps organizations streamline and automate the end-to-end machine learning lifecycle, from data ingestion and preparation to model training, deployment, monitoring, and governance. It promotes collaboration and coordination among data engineers, data scientists, machine learning engineers, and other stakeholders involved in the ML development process.\n",
      "\n",
      "The key benefits of MLOps include:\n",
      "\n",
      "1. Efficiency: MLOps enables faster model development, improved model quality, and quicker deployment and production of ML models.\n",
      "\n",
      "2. Scalability: With MLOps, organizations can handle thousands of models, ensuring reproducibility, collaboration, and efficient management of ML pipelines.\n",
      "\n",
      "3. Risk reduction: MLOps helps ensure compliance with regulatory requirements, transparency in model performance, and faster response to requests for model validation.\n",
      "\n",
      "MLOps also focuses on sustainable development, improving implementation through automation and reducing reliance on manual processes. It enables effective scaling of ML work and reduces waste by minimizing time and effort spent on irrelevant or misguided projects. Additionally, MLOps encourages collaboration among different data expertise, including data engineers, data scientists, machine learning engineers, and business stakeholders.\n",
      "\n",
      "Overall, MLOps plays a crucial role in enabling organizations to effectively develop, deploy, and manage machine learning models at scale, ensuring efficiency, scalability, risk reduction, and collaboration throughout the ML lifecycle.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # initialze Azure AI Search object \n",
    "    custom_search = CustomAzureSearch(\n",
    "        searchservice=searchservice,\n",
    "        searchkey=searchkey,\n",
    "        index_name=index_name,\n",
    "        number_results_to_return=3,\n",
    "        number_near_neighbors=3,\n",
    "        embedding_field_name=\"embedding\",\n",
    "        openai_api_key=openai_api_key,\n",
    "        embedding_model=\"text-embedding-ada-002\" \n",
    "    )\n",
    "\n",
    "    # initialize OpenAI Chat object \n",
    "    system_message = \"You are an assistant here to answer questions about the ebook: 'MLOps for Dummies: Databricks Special Edition'\" \n",
    "    openai_chat = OpenAIChat(\n",
    "        openai_api_key=openai_api_key,\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        system_message=system_message,\n",
    "        n=1,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    # initalize RAG model\n",
    "    model = RAGBot(\n",
    "        fields_to_return=[\"id\", \"sourcepage\", \"content\"],\n",
    "        azure_search_object=custom_search,\n",
    "        openai_chat_object=openai_chat\n",
    "    )\n",
    "\n",
    "    # perform RAG on query\n",
    "    query = \"tell me about mlops\" \n",
    "    response, memory = model(query)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
